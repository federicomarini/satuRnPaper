---
title: "1_Love_prepare"
author: "Jeroen Gilis"
date: "06/11/2020"
output: html_document
---

**In order to run this script (1_Love_prepare.Rmd), the folder Love_salmon.zip, which contains the salmon quantification files for this dataset, should be downloaded from Zenodo and unzipped. In addition, the metaData files Love_metadata.rda should also be downloaded from Zenodo. Both files must then be copied into the Data folder of this Github page.** Note that the quantification files were generated from the same reads as those from the paper by Love et al.[swimming downstream](https://doi.org/10.12688/f1000research.15398.3), however, they were quantified with a differrent version of salmon (salmon v1.1.0). The metadata file is an exact copy of the simulate.rda file from the Love et al. dataset.

**If one does not want to run this script, its output can also be downloaded from Zenodo: 02_Love_benchmark_datasets_count.Rdata**

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

# Load libraries

```{r,message=FALSE,warning=FASLE}
library(tximport)
library(DRIMSeq)
library(edgeR)
library(doMC)
library(BANDITS)
```

# Load data

```{r}
root.dir <- rprojroot::find_rstudio_root_file()

sample_names <- c("sample_01","sample_02","sample_03","sample_04","sample_05","sample_06","sample_07","sample_08","sample_09","sample_10","sample_11","sample_12","sample_13","sample_14","sample_15","sample_16","sample_17","sample_18","sample_19","sample_20","sample_21","sample_22","sample_23","sample_24")
quant_files <- file.path(root.dir, "Data/Love_salmon", sample_names, "quant.sf")
file.exists(quant_files)

txi <- tximport(files = quant_files, type = "salmon", countsFromAbundance = "no", txOut = TRUE)
#txi <- tximport(files = quant_files, type = "salmon", countsFromAbundance = "scaledTPM", txOut = TRUE)

myDesign <- data.frame(sample_id = as.character(sample_names),
                       condition = as.character(rep(c("group1","group2")),each=5))

colnames(txi$counts) <- myDesign$sample_id
```

# Load metadata

```{r}
load("./Data/Love_metadata.rda")

### Make our tx info copy (to match other benchmark data)
txInfo <- txdf[,2:1]
colnames(txInfo) <- c('isoform_id','gene_id')

txdf <- txdf[match(rownames(tpms), txdf$TXNAME),]
txdf$dtu.genes <- iso.dtu | iso.dte & !iso.dte.only
full.dtu.genes <- unique(txdf$GENEID[txdf$dtu.genes])

txp.exprs <- rowSums(tpms) > 0
dtu.dte.genes <- unique(txdf$GENEID[iso.dte & !iso.dte.only])
txdf$full.dtu <- iso.dtu | (txdf$GENEID %in% dtu.dte.genes & txp.exprs)
dtu.txps <- txdf$TXNAME[txdf$full.dtu] # Used as the truth in Love et al 2018

### Assign truth to our info df
txInfo$geneModified <- txInfo$isoform_id %in% dtu.txps
```

# Compute effective transcript leengths for BANDITS

```{r}
eff_len <- eff_len_compute(x_eff_len = txi$length)
saveRDS(eff_len, "./Data/Love_eff_len.Rds")

equiv_classes_files <- file.path(root.dir, "Data/Love_salmon", sample_names, "aux_info", "eq_classes.txt")
all(file.exists(equiv_classes_files))
```

# Setup generation of benchmark data

Set hyperparameters of the benchmark datasets (i.e. sample size, number of repeats, fraction of DTU genes and parameters for parallel processing).

```{r}
### Set parameters
samplesPrCondition   <- c(3,6,10)
nrRepsMade           <- 3
nrCoresToUse         <- 2

### Set up parallel processing
if(nrCoresToUse != 1) {
    doParallel <- TRUE
    doProgress <- 'none'

    registerDoMC(cores = nrCoresToUse)
} else {
    doParallel <- FALSE
    doProgress <- 'text'
}

### list for looping
nrRepList <- split(
    rep(
        x = samplesPrCondition,
        times = nrRepsMade
    ),
    paste0(
        'samples_used_',
        rep(
            x = samplesPrCondition,
            times = nrRepsMade
        ),
        '_rep_',
        sort( rep(
            x = 1:nrRepsMade,
            times = length(samplesPrCondition)
        ) )
    )
)
```

# Generate Love benchmark data

```{r}
source(file="./Performance_benchmarks/getBenchmark_data.R")
```

```{r}
LoveBenchmarkLenient <- getBenchmark_data(countData=txi$counts, 
                                          metaData=txInfo,
                                          filter="edgeR",
                                          edgeR_filter_spec = list(min.count = 10, 
                                                                    min.total.count = 15, 
                                                                    large.n = 10, 
                                                                    min.prop = 0.7),
                                          nrRepList=nrRepList, 
                                          fracGenesAffected=0.15)
names(LoveBenchmarkLenient) <- paste0(names(nrRepList),"_filterLenient")

LoveBenchmarkStringent <- getBenchmark_data(countData=txi$counts,
                                                metaData=txInfo,
                                                filter="DRIMSeq", 
                                                nrRepList=nrRepList, 
                                                fracGenesAffected=0.15)
names(LoveBenchmarkStringent) <- paste0(names(nrRepList),"_filterStringent")
```

# Save Tasic benchmark data

```{r}
save(LoveBenchmarkLenient, LoveBenchmarkStringent, file="./Data/02_Love_benchmark_datasets_count.Rdata")
#save(LoveBenchmarkLenient, LoveBenchmarkStringent, file="./Data/02_Love_benchmark_datasets_scaledTPM.Rdata")
```

